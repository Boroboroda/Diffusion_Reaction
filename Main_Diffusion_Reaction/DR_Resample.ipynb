{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import gridspec\n",
    "import random\n",
    "\n",
    "from Networks.DNN import PINN\n",
    "from Networks.IA_DNN import Attention_PINN\n",
    "from Networks.Fourier_DNN import Fourier_PINN\n",
    "from Networks.AF_PINN import AF_PINN\n",
    "from Networks.Efficient_KAN import KAN\n",
    "from Networks.Cheby_KAN import ChebyKAN\n",
    "from DataGenerator import DataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "seed_torch(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 600.0\n",
    "h = 100.0\n",
    "anneal_time= 60.0\n",
    "D_A = 360.0  #6nm^2/s 360nm^2/min\n",
    "k11,k12,k21 = 3.6e-3,3.6e-3,0.0\n",
    "N_SA,N_SB,N_SC,N_SAB,N_SABB,N_SAAB = 90.0,48.0,90.0,90.0,90.0,90.0\n",
    "\n",
    "geom = [0,L]\n",
    "time = [0,anneal_time]\n",
    "\n",
    "##How I genertate data\n",
    "generator = DataGenerator(geom,time)\n",
    "\n",
    "\n",
    "from pde_system import compute_pde, compute_bc, compute_ic,relative_error\n",
    "from graphics import plot_loss_curve,plot_relative_concen,plot_3d_concen\n",
    "# from Utilitiy.residual_adaptive_resample import select_high_loss_points\n",
    "\n",
    "true_path = './FDM/range[0,1]/'\n",
    "file_names = ['u1_output.csv','u2_output.csv','u3_output.csv','u4_output.csv','u5_output.csv','u6_output.csv']\n",
    "true_data = [pd.read_csv(true_path + file_name,header=None) for file_name in file_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN_4x[128]\n",
      "第1次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:17<00:00, 13.24it/s, Loss=1.484e-02, PDE=2.865e-03, BC=1.974e-03,2.591e-05, IC=9.362e-03,6.087e-04, D*=5.99e-02,5.09e-03, lr=9.76e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.081, 'SiC': 0.019, 'C': 0.086, 'NiSi': 0.177, 'NiSi2': 0.21}\n",
      "Inf Error: {'Ni': 0.078, 'SiC': 0.027, 'C': 0.17, 'NiSi': 0.274, 'NiSi2': 0.337}\n",
      "Mean Error: (0.1146246652643447, 0.17711078535206218)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 80.15s ---x采样特征：0.00,0.29 ---t采样特征:0.00,0.99\n",
      "第2次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:15<00:00, 13.30it/s, Loss=9.604e-03, PDE=2.693e-03, BC=2.375e-04,4.044e-06, IC=6.232e-03,4.376e-04, D*=6.00e-02,4.17e-03, lr=9.05e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.062, 'SiC': 0.022, 'C': 0.069, 'NiSi': 0.155, 'NiSi2': 0.163}\n",
      "Inf Error: {'Ni': 0.056, 'SiC': 0.023, 'C': 0.131, 'NiSi': 0.244, 'NiSi2': 0.268}\n",
      "Mean Error: (0.0941278809172095, 0.14436714363470554)\n",
      "第3次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:15<00:00, 13.31it/s, Loss=9.243e-03, PDE=3.434e-03, BC=1.800e-04,4.796e-05, IC=5.225e-03,3.564e-04, D*=6.00e-02,3.69e-03, lr=7.94e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.059, 'SiC': 0.018, 'C': 0.05, 'NiSi': 0.139, 'NiSi2': 0.139}\n",
      "Inf Error: {'Ni': 0.054, 'SiC': 0.018, 'C': 0.115, 'NiSi': 0.239, 'NiSi2': 0.243}\n",
      "Mean Error: (0.0811593525733646, 0.13379900581735077)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 82.51s ---x采样特征：0.00,0.26 ---t采样特征:0.00,0.53\n",
      "第4次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:19<00:00, 13.18it/s, Loss=7.222e-03, PDE=2.024e-03, BC=2.134e-04,1.343e-06, IC=4.670e-03,3.130e-04, D*=6.00e-02,3.44e-03, lr=6.55e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.049, 'SiC': 0.007, 'C': 0.054, 'NiSi': 0.131, 'NiSi2': 0.133}\n",
      "Inf Error: {'Ni': 0.048, 'SiC': 0.014, 'C': 0.115, 'NiSi': 0.213, 'NiSi2': 0.21}\n",
      "Mean Error: (0.07466668852027049, 0.12020980338646906)\n",
      "第5次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:18<00:00, 13.22it/s, Loss=6.949e-03, PDE=2.553e-03, BC=2.891e-05,4.389e-06, IC=4.079e-03,2.843e-04, D*=6.00e-02,3.29e-03, lr=5.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.045, 'SiC': 0.006, 'C': 0.06, 'NiSi': 0.126, 'NiSi2': 0.122}\n",
      "Inf Error: {'Ni': 0.045, 'SiC': 0.012, 'C': 0.12, 'NiSi': 0.199, 'NiSi2': 0.188}\n",
      "Mean Error: (0.07180427737725874, 0.11272004946767766)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 81.84s ---x采样特征：0.00,0.25 ---t采样特征:0.00,0.61\n",
      "第6次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:22<00:00, 13.06it/s, Loss=4.491e-03, PDE=1.112e-03, BC=5.657e-06,1.205e-06, IC=3.128e-03,2.441e-04, D*=6.00e-02,3.16e-03, lr=3.46e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.04, 'SiC': 0.005, 'C': 0.05, 'NiSi': 0.109, 'NiSi2': 0.116}\n",
      "Inf Error: {'Ni': 0.041, 'SiC': 0.009, 'C': 0.109, 'NiSi': 0.179, 'NiSi2': 0.171}\n",
      "Mean Error: (0.06398473915923797, 0.10191271932975729)\n",
      "第7次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:28<00:00, 12.86it/s, Loss=3.350e-03, PDE=6.540e-04, BC=4.174e-06,6.109e-07, IC=2.478e-03,2.133e-04, D*=6.00e-02,3.04e-03, lr=2.06e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.036, 'SiC': 0.005, 'C': 0.049, 'NiSi': 0.097, 'NiSi2': 0.111}\n",
      "Inf Error: {'Ni': 0.039, 'SiC': 0.007, 'C': 0.108, 'NiSi': 0.157, 'NiSi2': 0.15}\n",
      "Mean Error: (0.059686192218771784, 0.09219431711324433)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 87.82s ---x采样特征：0.00,0.30 ---t采样特征:0.00,0.79\n",
      "第8次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:51<00:00, 12.16it/s, Loss=2.602e-03, PDE=5.089e-04, BC=4.518e-06,5.623e-07, IC=1.894e-03,1.936e-04, D*=6.00e-02,2.94e-03, lr=9.57e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.034, 'SiC': 0.005, 'C': 0.048, 'NiSi': 0.088, 'NiSi2': 0.102}\n",
      "Inf Error: {'Ni': 0.037, 'SiC': 0.006, 'C': 0.104, 'NiSi': 0.138, 'NiSi2': 0.131}\n",
      "Mean Error: (0.05550415014994257, 0.08330875250483014)\n",
      "第9次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [07:06<00:00, 11.72it/s, Loss=2.042e-03, PDE=3.096e-04, BC=2.569e-06,4.991e-07, IC=1.551e-03,1.785e-04, D*=6.00e-02,2.87e-03, lr=2.46e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.034, 'SiC': 0.005, 'C': 0.047, 'NiSi': 0.083, 'NiSi2': 0.096}\n",
      "Inf Error: {'Ni': 0.036, 'SiC': 0.007, 'C': 0.1, 'NiSi': 0.126, 'NiSi2': 0.127}\n",
      "Mean Error: (0.052767826073712776, 0.07887967210199467)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 88.91s ---x采样特征：0.00,0.30 ---t采样特征:0.00,0.82\n",
      "第10次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:38<00:00, 12.53it/s, Loss=1.831e-03, PDE=2.354e-04, BC=2.601e-06,4.896e-07, IC=1.418e-03,1.752e-04, D*=6.00e-02,2.86e-03, lr=1.01e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.034, 'SiC': 0.005, 'C': 0.047, 'NiSi': 0.081, 'NiSi2': 0.094}\n",
      "Inf Error: {'Ni': 0.035, 'SiC': 0.007, 'C': 0.098, 'NiSi': 0.12, 'NiSi2': 0.124}\n",
      "Mean Error: (0.0520796078688749, 0.07691994080777995)\n",
      "IA_PINN_4x[128]\n",
      "第1次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:41<00:00,  5.31it/s, Loss=1.306e-02, PDE=5.420e-03, BC=6.601e-04,4.708e-05, IC=6.590e-03,3.446e-04, D*=6.00e-02,3.21e-03, lr=9.76e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.097, 'SiC': 0.025, 'C': 0.057, 'NiSi': 0.176, 'NiSi2': 0.129}\n",
      "Inf Error: {'Ni': 0.088, 'SiC': 0.03, 'C': 0.103, 'NiSi': 0.238, 'NiSi2': 0.243}\n",
      "Mean Error: (0.09674580880506511, 0.1404705493125853)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 171.74s ---x采样特征：0.00,0.25 ---t采样特征:0.00,0.45\n",
      "第2次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:27<00:00,  5.06it/s, Loss=8.201e-03, PDE=1.742e-03, BC=5.437e-04,1.578e-05, IC=5.632e-03,2.680e-04, D*=6.00e-02,3.10e-03, lr=9.05e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.081, 'SiC': 0.018, 'C': 0.054, 'NiSi': 0.145, 'NiSi2': 0.115}\n",
      "Inf Error: {'Ni': 0.075, 'SiC': 0.024, 'C': 0.078, 'NiSi': 0.174, 'NiSi2': 0.219}\n",
      "Mean Error: (0.0825675005660262, 0.11397557595705587)\n",
      "第3次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:26<00:00,  5.07it/s, Loss=6.774e-03, PDE=2.499e-03, BC=9.881e-05,1.259e-05, IC=3.976e-03,1.883e-04, D*=6.00e-02,2.65e-03, lr=7.94e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.053, 'SiC': 0.009, 'C': 0.038, 'NiSi': 0.105, 'NiSi2': 0.088}\n",
      "Inf Error: {'Ni': 0.051, 'SiC': 0.015, 'C': 0.074, 'NiSi': 0.173, 'NiSi2': 0.186}\n",
      "Mean Error: (0.05860921075274702, 0.09990268178794677)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 163.83s ---x采样特征：0.00,0.27 ---t采样特征:0.00,0.57\n",
      "第4次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:47<00:00,  5.27it/s, Loss=5.654e-03, PDE=1.488e-03, BC=3.805e-05,1.529e-05, IC=3.937e-03,1.762e-04, D*=6.00e-02,2.56e-03, lr=6.55e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.047, 'SiC': 0.006, 'C': 0.036, 'NiSi': 0.096, 'NiSi2': 0.089}\n",
      "Inf Error: {'Ni': 0.047, 'SiC': 0.014, 'C': 0.074, 'NiSi': 0.149, 'NiSi2': 0.18}\n",
      "Mean Error: (0.054774020435863456, 0.09266939619034036)\n",
      "第5次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:49<00:00,  5.26it/s, Loss=4.621e-03, PDE=1.386e-03, BC=6.739e-05,2.694e-06, IC=3.022e-03,1.435e-04, D*=6.00e-02,2.31e-03, lr=5.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.043, 'SiC': 0.007, 'C': 0.03, 'NiSi': 0.08, 'NiSi2': 0.083}\n",
      "Inf Error: {'Ni': 0.043, 'SiC': 0.012, 'C': 0.068, 'NiSi': 0.13, 'NiSi2': 0.163}\n",
      "Mean Error: (0.048650105350939936, 0.08316050588627484)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 160.21s ---x采样特征：0.00,0.26 ---t采样特征:0.00,1.00\n",
      "第6次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:04<00:00,  5.19it/s, Loss=3.914e-03, PDE=1.138e-03, BC=9.743e-06,4.355e-06, IC=2.635e-03,1.262e-04, D*=6.00e-02,2.16e-03, lr=3.46e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.041, 'SiC': 0.005, 'C': 0.027, 'NiSi': 0.074, 'NiSi2': 0.072}\n",
      "Inf Error: {'Ni': 0.041, 'SiC': 0.01, 'C': 0.061, 'NiSi': 0.118, 'NiSi2': 0.146}\n",
      "Mean Error: (0.04372190290457075, 0.07524493275840481)\n",
      "第7次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:07<00:00,  5.17it/s, Loss=2.898e-03, PDE=5.745e-04, BC=5.588e-06,4.254e-07, IC=2.211e-03,1.074e-04, D*=6.00e-02,2.00e-03, lr=2.06e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.038, 'SiC': 0.005, 'C': 0.024, 'NiSi': 0.067, 'NiSi2': 0.063}\n",
      "Inf Error: {'Ni': 0.039, 'SiC': 0.009, 'C': 0.054, 'NiSi': 0.105, 'NiSi2': 0.125}\n",
      "Mean Error: (0.039601933069401254, 0.06671180077464434)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 161.19s ---x采样特征：0.00,0.28 ---t采样特征:0.00,0.55\n",
      "第8次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:20<00:00,  5.10it/s, Loss=2.195e-03, PDE=2.946e-04, BC=3.677e-06,2.391e-07, IC=1.799e-03,9.737e-05, D*=6.00e-02,1.91e-03, lr=9.57e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.038, 'SiC': 0.004, 'C': 0.024, 'NiSi': 0.062, 'NiSi2': 0.057}\n",
      "Inf Error: {'Ni': 0.039, 'SiC': 0.008, 'C': 0.051, 'NiSi': 0.094, 'NiSi2': 0.11}\n",
      "Mean Error: (0.03719654037448317, 0.06040526544282175)\n",
      "第9次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:17<00:00,  5.11it/s, Loss=1.742e-03, PDE=1.367e-04, BC=3.362e-06,2.532e-07, IC=1.510e-03,9.146e-05, D*=6.00e-02,1.85e-03, lr=2.46e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.041, 'SiC': 0.005, 'C': 0.026, 'NiSi': 0.062, 'NiSi2': 0.053}\n",
      "Inf Error: {'Ni': 0.042, 'SiC': 0.009, 'C': 0.047, 'NiSi': 0.087, 'NiSi2': 0.1}\n",
      "Mean Error: (0.03722791758393436, 0.056968573403461654)\n",
      "开始重采样: 1\n",
      "结束重采样，用时: 161.61s ---x采样特征：0.00,0.28 ---t采样特征:0.00,0.56\n",
      "第10次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [17:16<00:00,  4.83it/s, Loss=1.715e-03, PDE=1.743e-04, BC=3.292e-06,3.785e-07, IC=1.445e-03,9.214e-05, D*=6.00e-02,1.86e-03, lr=1.01e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error: {'Ni': 0.038, 'SiC': 0.004, 'C': 0.035, 'NiSi': 0.065, 'NiSi2': 0.061}\n",
      "Inf Error: {'Ni': 0.039, 'SiC': 0.008, 'C': 0.057, 'NiSi': 0.088, 'NiSi2': 0.1}\n",
      "Mean Error: (0.040612924680272396, 0.05833032163078703)\n",
      "Fourier_PINN_4x[128]\n",
      "第1次重采样:----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1214/5000 [02:08<06:41,  9.44it/s, Loss=3.410e-02, PDE=8.271e-03, BC=4.339e-03,4.694e-05, IC=2.055e-02,8.964e-04, D*=5.99e-02,4.65e-03, lr=9.99e-04]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, norm_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 76\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# 如果使用scheduler（只在Adam阶段）\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:148\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 148\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    151\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m, in \u001b[0;36mclosure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# 计算损失时使用batch数据\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m loss_eq1, loss_eq2, loss_eq3, loss_eq4, loss_eq5, loss_eq6, D_star \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_pde\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords_pde\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m loss_pde \u001b[38;5;241m=\u001b[39m loss_eq1 \u001b[38;5;241m+\u001b[39m loss_eq2 \u001b[38;5;241m+\u001b[39m loss_eq3 \u001b[38;5;241m+\u001b[39m loss_eq4 \u001b[38;5;241m+\u001b[39m loss_eq5 \u001b[38;5;241m+\u001b[39m loss_eq6\n\u001b[0;32m     65\u001b[0m loss_bc1 \u001b[38;5;241m=\u001b[39m compute_bc(model, coords_bc1)\n",
      "File \u001b[1;32me:\\Report 12 Some Try\\Main_Diffusion_Reaction\\pde_system.py:47\u001b[0m, in \u001b[0;36mcompute_pde\u001b[1;34m(model, coords)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#Residuals of Governing Equations with Non-Dimensionalization\u001b[39;00m\n\u001b[0;32m     44\u001b[0m eq_1 \u001b[38;5;241m=\u001b[39m  dca_dt \u001b[38;5;241m-\u001b[39m gradients(D_star\u001b[38;5;241m*\u001b[39mdca_dx,coords)[:,\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     45\u001b[0m         k11 \u001b[38;5;241m*\u001b[39m(N_SA \u001b[38;5;241m*\u001b[39m N_SB\u001b[38;5;241m*\u001b[39m anneal_time) \u001b[38;5;241m/\u001b[39m N_SA\u001b[38;5;241m*\u001b[39m c_a \u001b[38;5;241m*\u001b[39m c_bc \u001b[38;5;241m+\u001b[39m k21\u001b[38;5;241m*\u001b[39m(N_SA \u001b[38;5;241m*\u001b[39m N_SAB \u001b[38;5;241m*\u001b[39manneal_time)\u001b[38;5;241m/\u001b[39mN_SA \u001b[38;5;241m*\u001b[39m c_a \u001b[38;5;241m*\u001b[39m c_ab\n\u001b[1;32m---> 47\u001b[0m eq_2 \u001b[38;5;241m=\u001b[39m dcbc_dt \u001b[38;5;241m-\u001b[39m\u001b[43mgradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_star\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdcbc_dx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     48\u001b[0m         k11\u001b[38;5;241m*\u001b[39m(N_SA \u001b[38;5;241m*\u001b[39m N_SB\u001b[38;5;241m*\u001b[39manneal_time)\u001b[38;5;241m/\u001b[39m N_SB \u001b[38;5;241m*\u001b[39m c_a \u001b[38;5;241m*\u001b[39m c_bc \u001b[38;5;241m+\u001b[39m k12\u001b[38;5;241m*\u001b[39m(N_SAB \u001b[38;5;241m*\u001b[39m N_SB\u001b[38;5;241m*\u001b[39manneal_time) \u001b[38;5;241m/\u001b[39mN_SB \u001b[38;5;241m*\u001b[39m c_ab \u001b[38;5;241m*\u001b[39m c_bc\n\u001b[0;32m     50\u001b[0m eq_3 \u001b[38;5;241m=\u001b[39m dcc_dt \u001b[38;5;241m-\u001b[39m gradients(D_star\u001b[38;5;241m*\u001b[39mdcc_dx,coords)[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\\\n\u001b[0;32m     51\u001b[0m         k11\u001b[38;5;241m*\u001b[39m(N_SA\u001b[38;5;241m*\u001b[39m N_SB \u001b[38;5;241m*\u001b[39manneal_time) \u001b[38;5;241m/\u001b[39mN_SC \u001b[38;5;241m*\u001b[39m c_a \u001b[38;5;241m*\u001b[39m c_bc \u001b[38;5;241m-\u001b[39m k12 \u001b[38;5;241m*\u001b[39m(N_SAB \u001b[38;5;241m*\u001b[39m N_SB\u001b[38;5;241m*\u001b[39manneal_time) \u001b[38;5;241m/\u001b[39m N_SC \u001b[38;5;241m*\u001b[39m c_ab \u001b[38;5;241m*\u001b[39m c_bc    \n\u001b[0;32m     53\u001b[0m eq_4 \u001b[38;5;241m=\u001b[39m dcab_dt \u001b[38;5;241m-\u001b[39m k11\u001b[38;5;241m*\u001b[39m(N_SA \u001b[38;5;241m*\u001b[39m N_SB \u001b[38;5;241m*\u001b[39manneal_time) \u001b[38;5;241m/\u001b[39m N_SAB \u001b[38;5;241m*\u001b[39mc_a \u001b[38;5;241m*\u001b[39mc_bc \u001b[38;5;241m+\u001b[39m k21 \u001b[38;5;241m*\u001b[39m(N_SA \u001b[38;5;241m*\u001b[39m N_SAB \u001b[38;5;241m*\u001b[39manneal_time)\u001b[38;5;241m/\u001b[39mN_SAB\u001b[38;5;241m*\u001b[39m c_a \u001b[38;5;241m*\u001b[39m c_ab \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     54\u001b[0m         k12\u001b[38;5;241m*\u001b[39m(N_SAB \u001b[38;5;241m*\u001b[39m N_SB\u001b[38;5;241m*\u001b[39manneal_time) \u001b[38;5;241m/\u001b[39mN_SAB \u001b[38;5;241m*\u001b[39m c_ab \u001b[38;5;241m*\u001b[39m c_bc\n",
      "File \u001b[1;32me:\\Report 12 Some Try\\Utilitiy\\gradients_func.py:5\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(u, x, order)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradients\u001b[39m(u, x, order \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gradients(gradients(u, x), x, order\u001b[38;5;241m=\u001b[39m order \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    409\u001b[0m         grad_outputs_\n\u001b[0;32m    410\u001b[0m     )\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[0;32m    425\u001b[0m     ):\n",
      "File \u001b[1;32md:\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hiddens = 4\n",
    "neurons = 128\n",
    "\n",
    "layer = [2] + [neurons]*hiddens + [6]\n",
    "activation = torch.nn.functional.tanh\n",
    "start_lr = 1e-3\n",
    "end_lr = 1e-8\n",
    "\n",
    "weight = [1, 1, 1, 1, 1]\n",
    "from torch import Tensor\n",
    "from pde_system import compute_pde, compute_bc, compute_ic\n",
    "from graphics import plot_loss_curve,plot_relative_concen,plot_3d_concen\n",
    "from Utilitiy.residual_adaptive_resample import select_high_loss_points\n",
    "\n",
    "for mode in ['PINN', 'IA_PINN', 'Fourier_PINN', 'AF_PINN']:  ##['PINN','IA_PINN','RES_PINN','RES_IA_PINN']\n",
    "    loss_log_total,loss_log_pde, loss_log_bc, loss_log_ic = [],[],[],[]\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'{mode}_{hiddens}x[{neurons}]')\n",
    "\n",
    "    num_epochs = 5000\n",
    "    resample_epochs = 10\n",
    "    \n",
    "    if mode == 'PINN':\n",
    "        model = PINN(layer,activation,non_negative=True).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=start_lr)  \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * resample_epochs, eta_min=end_lr)\n",
    "    elif mode == 'IA_PINN':\n",
    "        model = Attention_PINN(layer,activation,non_negative=True).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=start_lr)  \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * resample_epochs, eta_min=end_lr)\n",
    "    elif mode == 'Fourier_PINN':\n",
    "        model = Fourier_PINN(layer,activation, non_negative=True, use_rff=True, rff_num_features=neurons, rff_sigma=1.0).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=start_lr)  \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * resample_epochs, eta_min=end_lr)\n",
    "    elif mode == 'AF_PINN':\n",
    "        model = AF_PINN(layer, non_negative=True,activation = activation, use_rff=True, rff_num_features= neurons, rff_sigma=1.0).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=start_lr)  \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * resample_epochs, eta_min=end_lr)\n",
    "    else:\n",
    "        print(\"Man! What can I say! Wrong Mode!!!\")\n",
    "        break   \n",
    "\n",
    "    points_types = ['domain', 'left_bc', 'right_bc', 'initial']\n",
    "\n",
    "    coords_pde, coords_bc1, coords_bc2, coords_ic = [\n",
    "        generator.grid_generator(N=2500 if pt in ['left_bc', 'right_bc'] else 10201, points_type=pt, nondim= True) \n",
    "        for pt in points_types\n",
    "    ]\n",
    "\n",
    "    for idx in range(resample_epochs):\n",
    "        print('第{}次重采样:----------------------'.format(idx+1))\n",
    "        model.train()\n",
    "\n",
    "        pbar = tqdm(range(num_epochs))\n",
    "        \n",
    "        for epoch in pbar:\n",
    "            current_lr = optimizer.param_groups[0]['lr'] \n",
    "            def closure() -> Tensor:\n",
    "                global loss_pde, D_star, loss_bc1, loss_bc2, loss_ic1, loss_ic2\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 计算损失时使用batch数据\n",
    "                loss_eq1, loss_eq2, loss_eq3, loss_eq4, loss_eq5, loss_eq6, D_star = compute_pde(model, coords_pde)\n",
    "                loss_pde = loss_eq1 + loss_eq2 + loss_eq3 + loss_eq4 + loss_eq5 + loss_eq6\n",
    "                loss_bc1 = compute_bc(model, coords_bc1)\n",
    "                loss_bc2 = compute_bc(model, coords_bc2)\n",
    "                loss_ic1, loss_ic2 = compute_ic(model, coords_ic)\n",
    "\n",
    "                #Give a weight to initial loss term\n",
    "                loss = weight[0]*loss_pde +  weight[1]*loss_bc1 +  weight[2]*loss_bc2 +  weight[3]*loss_ic1 +  weight[4]*loss_ic2\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type= 2)\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure)\n",
    "            # 如果使用scheduler（只在Adam阶段）\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            loss_total = weight[0]*loss_pde +  weight[1]*loss_bc1 +  weight[2]*loss_bc2 +  weight[3]*loss_ic1 +  weight[4]*loss_ic2\n",
    "\n",
    "            loss_log_total.append(loss_total.item())\n",
    "            loss_log_pde.append(loss_pde.item())\n",
    "            loss_log_bc.append(loss_bc1.item() + loss_bc2.item())\n",
    "            loss_log_ic.append(loss_ic1.item() + loss_ic2.item())\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': '{0:.3e}'.format(loss_total.item()),\n",
    "                    'PDE': '{0:.3e}'.format(loss_pde.item()),\n",
    "                    'BC': '{0:.3e},{1:.3e}'.format(loss_bc1.item(),loss_bc2.item()),\n",
    "                    'IC': '{0:.3e},{1:.3e}'.format(loss_ic1.item(),loss_ic2.item()),\n",
    "                    'D*': '{0:.2e},{1:.2e}'.format(torch.max(D_star),torch.min(D_star)),\n",
    "                    'lr': '{0:.2e}'.format(current_lr),\n",
    "                }) \n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_data = generator.grid_generator(N =10201,points_type= 'domain', nondim= True)\n",
    "        result = model(val_data).data.cpu().numpy()\n",
    "        relative_error(result,true_data)\n",
    "\n",
    "        resample_nums = 0\n",
    "        if idx % 2 ==0:\n",
    "            resample_nums += 1\n",
    "            start_time = timeit.default_timer()\n",
    "            print(f\"开始重采样: {resample_nums}\")\n",
    "            resample_pde = generator.LHS_generator(5000, points_type='domain', nondim=True)\n",
    "            # resample_bc1 = generator.LHS_generator(1000, points_type='left_bc', nondim=True)\n",
    "            # resample_bc2 = generator.LHS_generator(1000, points_type='right_bc', nondim=True)\n",
    "            # resample_ic = generator.LHS_generator(5000, points_type='initial', nondim=True)\n",
    "\n",
    "            add_pde = select_high_loss_points(model, resample_points= resample_pde, n_select= 250, loss_type='pde')\n",
    "            # add_bc1 = select_high_loss_points(model, resample_points= resample_bc1, n_select= 200, loss_type='left_bc')\n",
    "            # add_bc2 = select_high_loss_points(model, resample_points= resample_bc2, n_select= 200, loss_type='right_bc')\n",
    "            # add_ic = select_high_loss_points(model, resample_points= resample_ic, n_select= 200, loss_type='initial')\n",
    "        \n",
    "            coords_pde = torch.cat((coords_pde, add_pde), dim=0)\n",
    "            # coords_bc1 = torch.cat((coords_bc1, add_bc1), dim=0)\n",
    "            # coords_bc2 = torch.cat((coords_bc2, add_bc2), dim=0)\n",
    "            # coords_ic = torch.cat((coords_ic, add_ic), dim=0)\n",
    "            \n",
    "            # 将四个张量放在一个列表中并随机打乱\n",
    "            shuffled_tensors = [tensor[torch.randperm(tensor.size(0))] for tensor in [coords_pde, coords_bc1, coords_bc2, coords_ic]]\n",
    "\n",
    "            # 解包到四个变量中\n",
    "            coords_pde, coords_bc1, coords_bc2, coords_ic = shuffled_tensors\n",
    "            \n",
    "            elapsed = timeit.default_timer() - start_time\n",
    "            print(\"结束重采样，用时: {0:.2f}s\".format(elapsed),'---x采样特征：{0:.2f},{1:.2f}'.format(torch.min(add_pde[:,0]),torch.max(add_pde[:,0])),'---t采样特征:{0:.2f},{1:.2f}'.format(torch.min(add_pde[:,1]),torch.max(add_pde[:,1])))\n",
    "        \n",
    "    # 绘制结果\n",
    "    plot_loss_curve(f'Re_[{neurons}]x{hiddens}_{mode}',loss_log_total,loss_log_pde, loss_log_bc, loss_log_ic)\n",
    "    \n",
    "    model.eval()\n",
    "    val_data = generator.grid_generator(N =10201,points_type= 'domain', nondim= True)\n",
    "    result = model(val_data).data.cpu().numpy()\n",
    "    \n",
    "    plot_relative_concen(f'Re_[{neurons}]x{hiddens}_{mode}',result,data_save=True)\n",
    "\n",
    "    \n",
    "    true_data = [pd.read_csv(true_path + file_name,header=None) for file_name in file_names]\n",
    "    plot_3d_concen(f'Re_[{neurons}]x{hiddens}_{mode}', result, true_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
